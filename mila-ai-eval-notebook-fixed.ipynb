{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36a824a4",
   "metadata": {},
   "source": [
    "## DOĞRULUK RAPORU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ==============================================================================\n",
    "# Adım 1: Kurulum\n",
    "# ==============================================================================\n",
    "print(\"--- Adım 1: Gerekli kütüphaneler ve Ollama kuruluyor... ---\")\n",
    "!pip install ollama pandas pydantic tqdm openpyxl -q\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Adım 2: Ollama Sunucusunu Başlatma ve Model Kontrolü\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Adım 2: Ollama sunucusu başlatılıyor ve Command-R modeli kontrol ediliyor... ---\")\n",
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "!pkill -f ollama\n",
    "!nohup ollama serve > ollama.log 2>&1 &\n",
    "print(\"Ollama sunucusunun başlatılması için 15 saniye bekleniyor...\")\n",
    "time.sleep(15)\n",
    "print(\"\\n--- Command-R modeli indiriliyor... ---\")\n",
    "pull_command = \"ollama pull command-r\"\n",
    "result = subprocess.run(pull_command, shell=True, capture_output=True, text=True)\n",
    "if result.returncode != 0:\n",
    "    print(\"--- HATA: Model indirilemedi. ---\"); print(\"Ollama'dan gelen hata mesajı:\", result.stderr)\n",
    "    raise RuntimeError(\"Ollama modeli 'command-r' indirilemedi.\")\n",
    "else:\n",
    "    print(\"--- Model başarıyla indirildi. ---\")\n",
    "print(\"\\n--- Sunucudaki modeller kontrol ediliyor... ---\")\n",
    "models_list_str = subprocess.check_output(\"ollama list\", shell=True, text=True)\n",
    "print(models_list_str)\n",
    "if \"command-r\" not in models_list_str:\n",
    "    raise RuntimeError(\"HATA: Model indirildi ancak listede görünmüyor.\")\n",
    "print(\"--- Kurulum ve model kontrolü başarıyla tamamlandı. ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Adım 3: Gerekli Kütüphaneler ve Veri Yükleme\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Adım 3: Kütüphaneler import ediliyor ve Excel dosyası isteniyor... ---\")\n",
    "import ollama\n",
    "import pandas as pd\n",
    "import json\n",
    "from pydantic import BaseModel, ValidationError, Field\n",
    "from typing import Literal, Dict, Any, List\n",
    "from google.colab import files\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import difflib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()\n",
    "\n",
    "print(\"Lütfen 'trendyol_mila.xlsx' dosyasını yükleyin.\")\n",
    "uploaded = files.upload()\n",
    "excel_filename = next((name for name in uploaded.keys() if name.endswith('.xlsx')), None)\n",
    "if not excel_filename:\n",
    "    raise ValueError(\"HATA: '.xlsx' uzantılı Excel dosyası yüklenmedi.\")\n",
    "df_sohbetler = pd.read_excel(excel_filename, sheet_name='sohbetler')\n",
    "df_mesajlar = pd.read_excel(excel_filename, sheet_name='mesajlar')\n",
    "print(\"--- Excel dosyası başarıyla yüklendi ve sayfalar okundu. ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Adım 4: Veri Ön İşleme (Sütun Adı Düzeltildi)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Adım 4: Veri ön işleme yapılıyor... ---\")\n",
    "def format_dialogue(messages: pd.DataFrame) -> str:\n",
    "    dialogue = []; messages = messages.sort_values(by='zaman')\n",
    "    for _, row in messages.iterrows():\n",
    "        dialogue.append(f\"{row['gonderen']}: {row['metin']}\")\n",
    "    return \"\\n\".join(dialogue)\n",
    "dialogues = df_mesajlar.groupby('sohbet_id').apply(format_dialogue).reset_index(name='metin')\n",
    "df_processed = pd.merge(df_sohbetler, dialogues, on='sohbet_id')\n",
    "def create_ground_truth_json(row: pd.Series) -> Dict[str, Any]:\n",
    "    return {\"yanit_durumu\": row[\"yanit_durumu\"], \"sentiment\": row[\"sentiment\"], \"tur\": row[\"tur\"], \"intent\": row[\"intent\"], \"intent_detay\": row[\"intent_detay\"]}\n",
    "df_processed['ground_truth'] = df_processed.apply(create_ground_truth_json, axis=1)\n",
    "print(f\"--- Toplam {len(df_processed)} adet sohbet analize hazır. ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Adım 5: Pydantic Şeması ve \"Ultimate\" Hibrit Prompt\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Adım 5: Pydantic şeması ve 'Ultimate' Hibrit Prompt hazırlanıyor... ---\")\n",
    "YANIT_DURUMU_ALLOWED=df_processed['yanit_durumu'].unique().tolist()\n",
    "SENTIMENT_ALLOWED=df_processed['sentiment'].unique().tolist()\n",
    "TUR_ALLOWED=df_processed['tur'].unique().tolist()\n",
    "INTENT_ALLOWED=df_processed['intent'].unique().tolist()\n",
    "INTENT_DETAY_ALLOWED=df_processed['intent_detay'].unique().tolist()\n",
    "\n",
    "class UltimateIntentSchema(BaseModel):\n",
    "    tur_aciklamasi: str = Field(description=\"Modelin 'tur' kategorisini neden seçtiğine dair kısa açıklaması.\")\n",
    "    yanit_durumu: Literal[tuple(YANIT_DURUMU_ALLOWED)]\n",
    "    sentiment: Literal[tuple(SENTIMENT_ALLOWED)]\n",
    "    tur: Literal[tuple(TUR_ALLOWED)]\n",
    "    intent: Literal[tuple(INTENT_ALLOWED)]\n",
    "    intent_detay: Literal[tuple(INTENT_DETAY_ALLOWED)]\n",
    "\n",
    "PROMPT_ULTIMATE = f\"\"\"SİSTEM ROLÜ: Sen, e-ticaret sohbetlerini analiz eden ve sana verilen KESİN kurallara göre yapılandırılmış bir JSON üreten, çok yetenekli bir uzmansın. Görevin, tüm kategorileri tek seferde, her biri için özel olarak tanımlanmış kurallara uyarak etiketlemektir.\n",
    "ÇIKTI FORMATI:\n",
    "{{\"tur_aciklamasi\": \"...\", \"yanit_durumu\": \"...\", \"sentiment\": \"...\", \"tur\": \"...\", \"intent\": \"...\", \"intent_detay\": \"...\"}}\n",
    "ALAN SÖZLÜKLERİ:\n",
    "- yanit_durumu ∈ {YANIT_DURUMU_ALLOWED}\n",
    "- sentiment ∈ {SENTIMENT_ALLOWED}\n",
    "- tur ∈ {TUR_ALLOWED}\n",
    "- intent ∈ {INTENT_ALLOWED}\n",
    "- intent_detay ∈ {INTENT_DETAY_ALLOWED}\n",
    "---\n",
    "### KATEGORİ BAZLI KARAR KURALLARI ###\n",
    "**1. 'Tur' Kategorisi İçin (Chain of Thought):**\n",
    "   - ÖNCE 'tur_aciklamasi' alanını doldur.\n",
    "   - **Baskın Ton Kuralı:** Sohbetin sonunda ne olursa olsun, müşterinin sergilediği **en olumsuz anı** baz al.\n",
    "   - **Duygu Eşiği Kuralı:** `Şikayet` için \"rezalet\", \"sinir bozucu\" gibi GÜÇLÜ olumsuz duygular ara. `Sorun` için \"çalışmıyor\", \"eksik geldi\" gibi daha SAKİN ifadeleri baz al. \"Can sıkıcı\" gibi hafif ifadeler 'Sorun'dur.\n",
    "   - Yaptığın açıklamaya uygun `tur` etiketini seç.\n",
    "**2. Diğer Kategoriler İçin:**\n",
    "   - **yanit_durumu**: Müşterinin ana problemi bot tarafından çözüldü mü, yoksa müşteri hala çözümsüz mü kaldı?\n",
    "   - **sentiment**: Konuşmanın genelindeki müşteri memnuniyetini ölç. Net bir memnuniyet (\"harika\") veya memnuniyetsizlik (\"berbat\") ifadesi ara. Nötr ifadeler 'Pozitif' sayılmaz.\n",
    "   - **intent / intent_detay**: Müşterinin **asıl ve kök amacını** belirle. \"Kargom gelmedi, iptal etmek istiyorum\" sohbetinde asıl amaç 'İptal'dir.\n",
    "---\n",
    "### AÇIKLAMALI ÖRNEKLER ###\n",
    "**Örnek 1:**\n",
    "SOHBET: Müşteri: Bunları zaten denedim! Sizinle konuşmak zaman kaybı oldu. Hiç yardımcı olmuyorsunuz.\n",
    "JSON ÇIKTISI:\n",
    "{{\n",
    "  \"tur_aciklamasi\": \"Müşteri 'zaman kaybı' gibi net suçlama ve güçlü olumsuz ifadeler kullandığı için bu bir Şikayet'tir.\",\n",
    "  \"yanit_durumu\": \"Çözülemedi\", \"sentiment\": \"Negatif\", \"tur\": \"Şikayet\", \"intent\": \"Kupon\", \"intent_detay\": \"Kupon kodunun çalışmaması\"\n",
    "}}\n",
    "**Örnek 2:**\n",
    "SOHBET: Müşteri: Siparişimde bir ürün eksik geldi. Ne yapmalıyım? Bot: ... Yeni ürününüz gönderilecektir. Müşteri: Harika, teşekkür ederim!\n",
    "JSON ÇIKTISI:\n",
    "{{\n",
    "  \"tur_aciklamasi\": \"Müşteri bir problem bildirmesine rağmen tonu sakin ve çözüm odaklıdır. Güçlü bir olumsuz duygu bulunmadığı için bu bir Sorun'dur.\",\n",
    "  \"yanit_durumu\": \"Çözüldü\", \"sentiment\": \"Pozitif\", \"tur\": \"Sorun\", \"intent\": \"Eksik ürün\", \"intent_detay\": \"Sipariş teslimatında eksik ürün\"\n",
    "}}\n",
    "---\n",
    "### GÖREV ###\n",
    "Şimdi, yukarıdaki TÜM kuralları ve örneklerdeki mantığı kullanarak aşağıdaki yeni sohbeti analiz et ve istenen 6 alanı içeren JSON çıktısını üret.\n",
    "SOHBET:\n",
    "<<DIALOG_BLOK>>\n",
    "\"\"\"\n",
    "print(\"--- 'Ultimate' Hibrit Prompt ve şema hazır. ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Adım 6: LLM Tahmin Fonksiyonu (Otomatik Düzeltme Özellikli)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Adım 6: Otomatik Düzeltmeli LLM tahmin fonksiyonu tanımlanıyor... ---\")\n",
    "client = ollama.Client()\n",
    "def find_closest_match(value: str, allowed_values: List[str]) -> str:\n",
    "    matches = difflib.get_close_matches(str(value), allowed_values, n=1, cutoff=0.8)\n",
    "    return matches[0] if matches else allowed_values[0]\n",
    "\n",
    "def get_prediction(dialogue: str) -> Dict[str, Any]:\n",
    "    full_prompt = PROMPT_ULTIMATE.replace(\"<<DIALOG_BLOK>>\", dialogue)\n",
    "    model_output = \"\"\n",
    "    try:\n",
    "        response = client.chat(model='command-r', messages=[{'role': 'user', 'content': full_prompt}], options={'temperature': 0.0}, format='json')\n",
    "        model_output = response['message']['content']\n",
    "        validated_output = UltimateIntentSchema.model_validate_json(model_output)\n",
    "        return validated_output.model_dump()\n",
    "    except ValidationError:\n",
    "        try:\n",
    "            raw_json = json.loads(model_output); corrected_data = {}\n",
    "            corrected_data['tur_aciklamasi'] = raw_json.get('tur_aciklamasi', 'Düzeltme sırasında açıklama üretilemedi.')\n",
    "            corrected_data['yanit_durumu'] = find_closest_match(raw_json.get('yanit_durumu'), YANIT_DURUMU_ALLOWED)\n",
    "            corrected_data['sentiment'] = find_closest_match(raw_json.get('sentiment'), SENTIMENT_ALLOWED)\n",
    "            corrected_data['tur'] = find_closest_match(raw_json.get('tur'), TUR_ALLOWED)\n",
    "            corrected_data['intent'] = find_closest_match(raw_json.get('intent'), INTENT_ALLOWED)\n",
    "            corrected_data['intent_detay'] = find_closest_match(raw_json.get('intent_detay'), INTENT_DETAY_ALLOWED)\n",
    "            validated_output = UltimateIntentSchema.model_validate(corrected_data)\n",
    "            return validated_output.model_dump()\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Pydantic Hatası (Düzeltilemedi): {str(e)}\", \"original_output\": model_output}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Beklenmedik hata: {str(e)}\"}\n",
    "\n",
    "print(\"--- Tahmin fonksiyonu hazır. ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Adım 7: Ana İşlem Döngüsü\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Adım 7: Tüm sohbetler için tahminler alınıyor... ---\")\n",
    "df_processed['prediction'] = df_processed['metin'].progress_apply(get_prediction)\n",
    "print(\"--- Tüm tahminler başarıyla alındı! ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# YENİ Adım 8: Etiket Birleştirme Adımı\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Adım 8: 'Tur' etiketleri birleştiriliyor... ---\")\n",
    "\n",
    "tur_map = {\n",
    "    'Şikayet': 'Problem',\n",
    "    'Sorun': 'Problem',\n",
    "    'Soru': 'Sorgu',\n",
    "    'Bilgi alma': 'Sorgu',\n",
    "    'İstek': 'İstek',\n",
    "    'İade': 'İade'\n",
    "}\n",
    "\n",
    "def merge_tur_labels(data_dict):\n",
    "    if not isinstance(data_dict, dict) or 'error' in data_dict or 'tur' not in data_dict:\n",
    "        return data_dict\n",
    "\n",
    "    merged_dict = data_dict.copy()\n",
    "    original_tur = merged_dict['tur']\n",
    "    merged_dict['tur'] = tur_map.get(original_tur, original_tur)\n",
    "    return merged_dict\n",
    "\n",
    "df_processed['ground_truth_merged'] = df_processed['ground_truth'].apply(merge_tur_labels)\n",
    "df_processed['prediction_merged'] = df_processed['prediction'].apply(merge_tur_labels)\n",
    "print(\"--- Etiket birleştirme tamamlandı. ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Adım 9: Sonuçların Değerlendirilmesi ve Raporlanması\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Adım 9: Sonuçlar birleştirilmiş etiketlere göre değerlendiriliyor... ---\")\n",
    "correct_predictions = {'yanit_durumu': 0, 'sentiment': 0, 'tur': 0, 'intent': 0, 'intent_detay': 0}\n",
    "overall_correct = 0; total_processed = 0\n",
    "for _, row in df_processed.iterrows():\n",
    "    truth = row['ground_truth_merged']\n",
    "    pred = row['prediction_merged']\n",
    "\n",
    "    if 'error' in pred: continue\n",
    "    total_processed += 1\n",
    "\n",
    "    results = {key: truth[key] == pred.get(key) for key in truth}\n",
    "    for key, is_correct in results.items():\n",
    "        if is_correct: correct_predictions[key] += 1\n",
    "    if all(results.values()): overall_correct += 1\n",
    "\n",
    "print(\"\\n\" + \"=\"*40); print(\"     DOĞRULUK RAPORU (BİRLEŞTİRİLMİŞ 'TUR' İLE)\"); print(\"=\"*40)\n",
    "if total_processed > 0:\n",
    "    for key, value in correct_predictions.items():\n",
    "        if key == 'tur':\n",
    "            print(f\"{'Tur (Problem/Sorgu)':<25}: {(value / total_processed) * 100:.2f}%\")\n",
    "        else:\n",
    "            print(f\"{key.capitalize():<25}: {(value / total_processed) * 100:.2f}%\")\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"{'Genel Accuracy':<25}: {(overall_correct / total_processed) * 100:.2f}%\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Toplam {total_processed}/{len(df_processed)} sohbet başarıyla değerlendirildi.\")\n",
    "else:\n",
    "    print(\"Hiçbir sohbet başarıyla değerlendirilemedi.\")\n",
    "print(\"\\n--- Analiz tamamlandı. ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# Adım 10: Sonuçları Dosyaya Kaydetme\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Adım 10: Sonuçlar CSV dosyasına kaydediliyor... ---\")\n",
    "results_filename = 'llm_final.csv'\n",
    "\n",
    "df_to_save = df_processed.copy()\n",
    "for col in ['ground_truth', 'prediction', 'ground_truth_merged', 'prediction_merged']:\n",
    "    df_to_save[col] = df_to_save[col].apply(lambda x: json.dumps(x, ensure_ascii=False) if isinstance(x, dict) else x)\n",
    "\n",
    "df_to_save.to_csv(\n",
    "    results_filename,\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "files.download(results_filename)\n",
    "print(f\"\\nİşlem tamamlandı! Detaylı sonuçlar '{results_filename}' dosyasına kaydedildi ve indirme başlatıldı.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f1c1ed",
   "metadata": {},
   "source": [
    "## KATEGORİ BAZLI PERFORMANS RAPORLARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727027ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# -*- coding: utf-8 -*-\n",
    "# ==============================================================================\n",
    "# Adım 1: Gerekli Kütüphanelerin Kurulumu\n",
    "# ==============================================================================\n",
    "print(\"--- Adım 1: Gerekli kütüphaneler kuruluyor... ---\")\n",
    "!pip install pandas seaborn matplotlib numpy openpyxl -q\n",
    "print(\"--- Kurulum tamamlandı. ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Adım 2: Kütüphanelerin Import Edilmesi ve Sonuç CSV Dosyasının Yüklenmesi\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Adım 2: Kütüphaneler import ediliyor ve analiz sonuç dosyası isteniyor... ---\")\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Lütfen LLM analizi sonucunda indirdiğiniz 'llm_final.csv' gibi bir CSV dosyasını yükleyin.\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "csv_filename = next((name for name in uploaded.keys() if name.endswith('.csv')), None)\n",
    "if not csv_filename:\n",
    "    raise ValueError(\"HATA: '.csv' uzantılı sonuç dosyası yüklenmedi.\")\n",
    "\n",
    "df = pd.read_csv(csv_filename)\n",
    "print(f\"--- '{csv_filename}' dosyası başarıyla yüklendi. ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Adım 3: Veriyi Görselleştirmeye Hazırlama\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Adım 3: Veri işleniyor ve grafikler için hazırlanıyor... ---\")\n",
    "\n",
    "categories = ['yanit_durumu', 'sentiment', 'tur', 'intent', 'intent_detay']\n",
    "\n",
    "def parse_json_string(s):\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except (json.JSONDecodeError, TypeError, AttributeError):\n",
    "        return None\n",
    "\n",
    "df['gt_dict'] = df['ground_truth_merged'].apply(parse_json_string)\n",
    "df['pred_dict'] = df['prediction_merged'].apply(parse_json_string)\n",
    "\n",
    "df.dropna(subset=['gt_dict', 'pred_dict'], inplace=True)\n",
    "df = df[df['pred_dict'].apply(lambda x: 'error' not in x if isinstance(x, dict) else True)]\n",
    "\n",
    "for cat in categories:\n",
    "    df[f'gt_{cat}'] = df['gt_dict'].apply(lambda x: x.get(cat) if isinstance(x, dict) else None)\n",
    "    df[f'pred_{cat}'] = df['pred_dict'].apply(lambda x: x.get(cat) if isinstance(x, dict) else None)\n",
    "\n",
    "print(\"--- Veri işleme tamamlandı. Grafik çizimine hazır. ---\")\n",
    "# ==============================================================================\n",
    "# Adım 4 (Versiyon 6.1 - DÜZELTİLMİŞ): Kapsamlı Performans Dashboard'ları\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Adım 4 (Versiyon 6.1 - DÜZELTİLMİŞ): Her Kategori için Kapsamlı Dashboard'lar Oluşturuluyor... ---\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "category_colors = {\n",
    "    'yanit_durumu': '#3498db', 'sentiment': '#2ecc71', 'tur': '#e74c3c',\n",
    "    'intent': '#9b59b6', 'intent_detay': '#f39c12'\n",
    "}\n",
    "TOP_N = 8\n",
    "\n",
    "for category in categories:\n",
    "    if df[f'gt_{category}'].dropna().empty:\n",
    "        print(f\"--- '{category}' kategorisi için yeterli veri bulunamadı, atlanıyor. ---\")\n",
    "        continue\n",
    "\n",
    "    # === 1. Veri Hazırlığı (Bu kategoriye özel) ===\n",
    "    base_color = category_colors.get(category, '#34495e')\n",
    "    title_cat = category.replace('_', ' ').title()\n",
    "\n",
    "    # --- 1a. Genel Doğruluk Verisi ---\n",
    "    correct = (df[f'gt_{category}'] == df[f'pred_{category}']).sum()\n",
    "    total = len(df.dropna(subset=[f'gt_{category}', f'pred_{category}']))\n",
    "    accuracy = (correct / total) if total > 0 else 0\n",
    "\n",
    "    # --- 1b. Dağılım Karşılaştırma Verisi ---\n",
    "    gt_counts = df[f'gt_{category}'].value_counts().reset_index(); gt_counts.columns = ['label', 'Manuel Etiket']\n",
    "    pred_counts = df[f'pred_{category}'].value_counts().reset_index(); pred_counts.columns = ['label', 'LLM Tahmini']\n",
    "    combined_df = pd.merge(gt_counts, pred_counts, on='label', how='outer').fillna(0)\n",
    "    combined_df['fark'] = abs(combined_df['Manuel Etiket'] - combined_df['LLM Tahmini'])\n",
    "    top_diff_df = combined_df.sort_values(by='fark', ascending=False).head(TOP_N)\n",
    "    tidy_df = top_diff_df.drop(columns=['fark']).melt(id_vars='label', var_name='Kaynak', value_name='Sayı')\n",
    "\n",
    "    # --- 1c. Hata Analizi Verisi ---\n",
    "    accuracy_data = []\n",
    "    temp_df = df.dropna(subset=[f'gt_{category}'])\n",
    "    labels_for_acc = temp_df[f'gt_{category}'].value_counts().head(TOP_N).index\n",
    "    for label in labels_for_acc:\n",
    "        label_df = temp_df[temp_df[f'gt_{category}'] == label]\n",
    "        total_label = len(label_df)\n",
    "        correct_label = (label_df[f'gt_{category}'] == label_df[f'pred_{category}']).sum()\n",
    "        accuracy_data.append({'label': label, 'Doğru Tahmin': correct_label, 'Gözden Kaçırılan': total_label - correct_label})\n",
    "    acc_df = pd.DataFrame(accuracy_data).sort_values(by='Doğru Tahmin')\n",
    "\n",
    "\n",
    "    # === 2. Dashboard Çizimi ===\n",
    "    fig = plt.figure(figsize=(18, 16), constrained_layout=True)\n",
    "    gs = gridspec.GridSpec(2, 2, figure=fig, height_ratios=[0.7, 1])\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax3 = fig.add_subplot(gs[1, :])\n",
    "\n",
    "    fig.suptitle(f\"'{title_cat}' Kategorisi Performans Raporu\", fontsize=30, weight='bold', color=base_color)\n",
    "\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title('Genel Kategori Doğruluğu', fontsize=18, style='italic')\n",
    "    ax1.text(0.5, 0.5, f'{accuracy:.1%}', ha='center', va='center', fontsize=80, weight='bold', color=base_color)\n",
    "    ax1.text(0.5, 0.2, f'({correct} doğru / {total} toplam)', ha='center', va='center', fontsize=16, color='grey')\n",
    "\n",
    "    palette = sns.light_palette(base_color, n_colors=2, reverse=True)\n",
    "    sns.barplot(data=tidy_df, y='label', x='Sayı', hue='Kaynak', palette=palette, orient='h', ax=ax2)\n",
    "    ax2.set_title(f'Etiket Dağılımı', fontsize=18, style='italic')\n",
    "    ax2.set_ylabel('')\n",
    "    ax2.set_xlabel('Sohbet Sayısı')\n",
    "\n",
    "    ax3.barh(acc_df['label'], acc_df['Doğru Tahmin'], color=base_color, label='Doğru Tahmin')\n",
    "    ax3.barh(acc_df['label'], acc_df['Gözden Kaçırılan'], left=acc_df['Doğru Tahmin'], color='#E5E7EB', label='Gözden Kaçırılan')\n",
    "    ax3.set_title(f'Etiket Bazında Hata Analizi', fontsize=18, style='italic')\n",
    "    ax3.set_xlabel('Sohbet Sayısı')\n",
    "    ax3.legend()\n",
    "\n",
    "    filename = f\"dashboard_{category}_raporu.png\"\n",
    "    plt.savefig(filename, dpi=120)\n",
    "    plt.show()\n",
    "    print(f\"'{filename}' oluşturuldu.\")\n",
    "\n",
    "print(\"\\n--- Kategori Raporları Tamamlandı. ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Adım 5: Genel Performans Özeti (Radar Grafiği)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Adım 5: Tüm Kategorileri Özetleyen Radar Grafiği Oluşturuluyor... ---\")\n",
    "\n",
    "performance_metrics = {}\n",
    "for cat in categories:\n",
    "    correct = (df[f'gt_{cat}'] == df[f'pred_{cat}']).sum()\n",
    "    total = len(df.dropna(subset=[f'gt_{cat}', f'pred_{cat}']))\n",
    "    accuracy = (correct / total) * 100 if total > 0 else 0\n",
    "    performance_metrics[cat.replace('_', ' ').title()] = accuracy\n",
    "\n",
    "labels = list(performance_metrics.keys())\n",
    "values = list(performance_metrics.values())\n",
    "values += values[:1]\n",
    "labels_with_values = [f\"{label}\\n({value:.1f}%)\" for label, value in performance_metrics.items()]\n",
    "\n",
    "num_vars = len(labels)\n",
    "angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "angles += angles[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(polar=True))\n",
    "ax.plot(angles, values, color='#c0392b', linewidth=2)\n",
    "ax.fill(angles, values, color='#e74c3c', alpha=0.25)\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(labels_with_values, size=14)\n",
    "plt.title(\"Tüm Kategorilerin Genel Doğruluk Profili (%)\", size=22, weight='bold', y=1.1)\n",
    "ax.set_rgrids([25, 50, 75, 100], labels=[\"25%\", \"50%\", \"75%\", \"100%\"], angle=0, color=\"darkgrey\", size=10)\n",
    "ax.set_ylim(0, 100)\n",
    "\n",
    "filename = \"dashboard_genel_ozet_radar.png\"\n",
    "plt.savefig(filename, dpi=120)\n",
    "plt.show()\n",
    "\n",
    "print(f\"'{filename}' oluşturuldu.\")\n",
    "print(\"\\n--- Tüm Raporlama İşlemleri Tamamlandı. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263791e3",
   "metadata": {},
   "source": [
    "## KARŞILAŞTIRMALI EXCEL DOSYASI OLUŞTURMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9455995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Adım 1: Gerekli Kütüphanelerin Kurulumu ve Import Edilmesi\n",
    "# ==============================================================================\n",
    "print(\"--- Adım 1: Gerekli kütüphaneler kuruluyor ve import ediliyor... ---\")\n",
    "!pip install pandas openpyxl -q\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from google.colab import files\n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "print(\"--- Kurulum ve import işlemleri tamamlandı. ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Adım 2: Gerekli Dosyaların Yüklenmesi (2 DOSYA)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Adım 2: Lütfen gerekli dosyaları yükleyin... ---\")\n",
    "\n",
    "print(\"Lütfen manuel etiketleri ve sohbet metinlerini içeren 'ground_truth.xlsx' dosyasını yükleyin.\")\n",
    "uploaded_gt = files.upload()\n",
    "gt_filename = next(iter(uploaded_gt))\n",
    "df_ground_truth = pd.read_excel(gt_filename, sheet_name='sohbetler')\n",
    "print(f\"--- '{gt_filename}' dosyası başarıyla yüklendi. ---\")\n",
    "\n",
    "print(\"\\nLütfen yapay zekâ tahminlerini içeren 'llm_final.csv' dosyasını yükleyin.\")\n",
    "uploaded_llm = files.upload()\n",
    "llm_filename = next(iter(uploaded_llm))\n",
    "df_llm = pd.read_csv(llm_filename)\n",
    "print(f\"--- '{llm_filename}' dosyası başarıyla yüklendi. ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Adım 3: Verilerin İşlenmesi ve Birleştirilmesi (NİHAİ DÜZELTME)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Adım 3: Veriler işleniyor ve karşılaştırma tablosu hazırlanıyor... ---\")\n",
    "\n",
    "# --- DÜZELTME BAŞLANGICI: Sağlam Birleştirme Mantığı ---\n",
    "\n",
    "# 1. Veri tiplerini birleştirmeden önce eşitleyelim (En yaygın hata nedenlerinden biri)\n",
    "df_ground_truth['sohbet_id'] = df_ground_truth['sohbet_id'].astype(str)\n",
    "if 'id' in df_llm.columns and 'sohbet_id' not in df_llm.columns:\n",
    "    df_llm.rename(columns={'id': 'sohbet_id'}, inplace=True)\n",
    "df_llm['sohbet_id'] = df_llm['sohbet_id'].astype(str)\n",
    "\n",
    "# 2. Gerekli sütunları seçerek temiz kopyalar oluşturalım\n",
    "sohbet_metni_sutunu = 'tam_sohbet' # Sütun adının bu olduğunu teyit ettik\n",
    "categories = ['yanit_durumu', 'sentiment', 'tur', 'intent', 'intent_detay']\n",
    "gt_cols_to_keep = ['sohbet_id', sohbet_metni_sutunu] + categories\n",
    "df_gt_clean = df_ground_truth[gt_cols_to_keep].copy()\n",
    "\n",
    "llm_cols_to_keep = ['sohbet_id', 'prediction', 'prediction_merged']\n",
    "df_llm_clean = df_llm[llm_cols_to_keep].copy()\n",
    "\n",
    "# 3. Temiz kopyaları birleştirelim\n",
    "df_comparison = pd.merge(df_gt_clean, df_llm_clean, on='sohbet_id', how='left')\n",
    "\n",
    "# --- DÜZELTME SONU ---\n",
    "\n",
    "\n",
    "# Sütun adlarını daha anlaşılır hale getirelim\n",
    "df_comparison.rename(columns={cat: f\"Manual_{cat}\" for cat in categories}, inplace=True)\n",
    "df_comparison.rename(columns={sohbet_metni_sutunu: 'Sohbet_Metni'}, inplace=True)\n",
    "\n",
    "# LLM tahminlerini ve Eşleşme durumlarını yeni sütunlar olarak ekleyelim\n",
    "def parse_json_string(s):\n",
    "    try: return json.loads(s)\n",
    "    except: return {}\n",
    "\n",
    "df_comparison['prediction_dict'] = df_comparison['prediction'].apply(parse_json_string)\n",
    "df_comparison['prediction_merged_dict'] = df_comparison['prediction_merged'].apply(parse_json_string)\n",
    "\n",
    "for cat in categories:\n",
    "    df_comparison[f'LLM_{cat}'] = df_comparison['prediction_dict'].apply(lambda x: x.get(cat, 'N/A') if isinstance(x, dict) else 'N/A')\n",
    "    df_comparison[f'LLM_Merged_{cat}'] = df_comparison['prediction_merged_dict'].apply(lambda x: x.get(cat, 'N/A') if isinstance(x, dict) else 'N/A')\n",
    "    # Artık 'Manual_...' sütunları hatasız bulunacaktır\n",
    "    df_comparison[f'Eşleşme_{cat}'] = df_comparison[f'Manual_{cat}'] == df_comparison[f'LLM_Merged_{cat}']\n",
    "\n",
    "# Nihai raporda gösterilecek sütunları belirleyip sıralayalım\n",
    "manual_cols = [f'Manual_{cat}' for cat in categories]\n",
    "llm_cols = [f'LLM_{cat}' for cat in categories]\n",
    "llm_merged_cols = [f'LLM_Merged_{cat}' for cat in categories]\n",
    "match_cols = [f'Eşleşme_{cat}' for cat in categories]\n",
    "\n",
    "final_columns_to_keep = ['sohbet_id', 'Sohbet_Metni'] + manual_cols + llm_merged_cols + llm_cols + match_cols\n",
    "df_comparison = df_comparison[final_columns_to_keep]\n",
    "\n",
    "print(\"--- Veri işleme ve birleştirme tamamlandı. ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Adım 4: Renklendirilmiş Excel Dosyasının Oluşturulması\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Adım 4: Renklendirilmiş Excel dosyası oluşturuluyor... ---\")\n",
    "\n",
    "output_filename = 'Karsilastirmali_Analiz_Raporu_Nihai.xlsx'\n",
    "writer = pd.ExcelWriter(output_filename, engine='openpyxl')\n",
    "df_comparison.to_excel(writer, sheet_name='Karsilastirma', index=False)\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['Karsilastirma']\n",
    "\n",
    "green_fill = PatternFill(start_color='C6EFCE', end_color='C6EFCE', fill_type='solid')\n",
    "red_fill = PatternFill(start_color='FFC7CE', end_color='FFC7CE', fill_type='solid')\n",
    "\n",
    "for col_idx, col_name in enumerate(df_comparison.columns, 1):\n",
    "    if col_name.startswith('LLM_Merged_'):\n",
    "        match_col_name = col_name.replace('LLM_Merged_', 'Eşleşme_')\n",
    "        match_col_values = df_comparison[match_col_name]\n",
    "\n",
    "        for row_idx, matches in enumerate(match_col_values, 2):\n",
    "            cell = worksheet.cell(row=row_idx, column=col_idx)\n",
    "            # Eşleşme durumu True/False olmayan (NaN gibi) durumları kontrol et\n",
    "            if pd.isna(matches):\n",
    "                continue\n",
    "            if matches:\n",
    "                cell.fill = green_fill\n",
    "            else:\n",
    "                cell.fill = red_fill\n",
    "\n",
    "for column in worksheet.columns:\n",
    "    max_length = 0\n",
    "    column_letter = column[0].column_letter\n",
    "\n",
    "    if column[0].value == 'Sohbet_Metni':\n",
    "        worksheet.column_dimensions[column_letter].width = 60\n",
    "        for cell in column:\n",
    "            if cell.row > 1:\n",
    "                cell.alignment = cell.alignment.copy(wrap_text=True)\n",
    "        continue\n",
    "\n",
    "    for cell in column:\n",
    "        try:\n",
    "            if len(str(cell.value)) > max_length:\n",
    "                max_length = len(str(cell.value))\n",
    "        except:\n",
    "            pass\n",
    "    adjusted_width = (max_length + 2)\n",
    "    worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "writer.close()\n",
    "print(f\"--- '{output_filename}' dosyası başarıyla oluşturuldu! ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Adım 5: Oluşturulan Dosyanın İndirilmesi\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Adım 5: Oluşturulan Excel dosyası indiriliyor... ---\")\n",
    "files.download(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c95626",
   "metadata": {},
   "source": [
    "## NOT:\n",
    "'tur' için birleştirilen kategoriler:\n",
    "\n",
    "'Problem' başlığı altında birleştirilenler:\n",
    "\n",
    "*   Şikayet\n",
    "*   Sorun\n",
    "\n",
    "\n",
    "'Sorgu' başlığı altında birleştirilenler:\n",
    "\n",
    "*   Soru\n",
    "*   Bilgi alma"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
